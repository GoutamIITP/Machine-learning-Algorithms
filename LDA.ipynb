{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMp+eVRBhXkCbnMb7kbWBSi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Name = Goutam Kumar Sah\n","\n","Roll Number = 2312res271\n","\n","Experiment No = 9\n","\n","Title = Linear Discriminant Analysis (LDA)\n","\n","Aim = Implementation of Linear Discriminant Analysis (LDA) Algorithm"],"metadata":{"id":"zB0Ufc9aszKd"}},{"cell_type":"markdown","source":["# Theory"],"metadata":{"id":"lYef8LdHszGo"}},{"cell_type":"markdown","source":["*  Linear Discriminant Analysis (LDA) is a supervised dimensionality reduction technique used for\n","classification and feature extraction. It aims to find the linear combinations of features that best\n","separate different classes in a dataset. LDA is often used as a preprocessing step before applying\n","classification algorithms to improve their performance\n","\n","* It is used to project the features in higher dimension space into a\n","lower dimension space.\n","\n","**Key Concepts:**\n","\n","1. Supervised Nature: LDA uses class labels to find a linear combination of features that best separates the data points from different classes.\n","\n","2. Maximizing Separability: The goal is to maximize the distance between means of different classes (inter-class variance) while minimizing the scatter within each class (intra-class variance).\n","\n","3. Feature Projection: LDA projects the data from a higher-dimensional space into a lower-dimensional space while ensuring that the classes remain as separable as possible.\n","\n","**Applications**: LDA is widely used for reducing dimensionality in high-dimensional datasets while retaining most class-related information. It’s often applied in areas such as:\n","\n"," * Face Recognition: Distinguishing between images of different individuals.\n","\n"," * Speech Recognition: Differentiating between different speakers or spoken words.\n","\n"," * Bioinformatics: Classifying types of genes or protein expressions."],"metadata":{"id":"ZWRfVgdysy7a"}},{"cell_type":"markdown","source":["LDA Algorithm Steps :\n","\n","1. Compute the class means of dependent variable\n","\n","2. Derive the covariance matrix of the class variable\n","\n","3. Compute the within class — scatter matrix\n","(Sl+S2)\n","\n","4. Compute the between class scatter matrix\n","\n","5. Compute the Eigen values and eigen vectors\n","from the within class and between class scatter\n","matrix\n","\n","6. Sort the values of eigen values and select\n","the top k values\n","\n","7. Find the eigen vectors corresponds to the\n","top k eigen vectors.\n","\n","8. Obtain the LDA by taking the dot product of\n","eigen vectors and original data"],"metadata":{"id":"Ss6jEjoavprs"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8wBK3xCsrn5","executionInfo":{"status":"ok","timestamp":1730570214999,"user_tz":-330,"elapsed":1723,"user":{"displayName":"Gk sah","userId":"05182244052629094637"}},"outputId":"fb2fff03-a122-4046-b113-4ddd8ca41ae3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Transformed Data:\n"," [[-1.49920971+0.j -1.88675441+0.j]\n"," [-1.2643595 +0.j -1.59214275+0.j]\n"," [-1.35525305+0.j -1.73341462+0.j]\n"," [-1.18495616+0.j -1.62358806+0.j]\n"," [-1.5169559 +0.j -1.94476227+0.j]\n"," [-1.40864014+0.j -2.20148038+0.j]\n"," [-1.28548339+0.j -1.90177269+0.j]\n"," [-1.38431399+0.j -1.80218401+0.j]\n"," [-1.12136823+0.j -1.53021571+0.j]\n"," [-1.31831374+0.j -1.54860234+0.j]\n"," [-1.58367182+0.j -1.98077996+0.j]\n"," [-1.28716445+0.j -1.77562146+0.j]\n"," [-1.31422036+0.j -1.51454424+0.j]\n"," [-1.37605297+0.j -1.58704672+0.j]\n"," [-1.94923317+0.j -2.23514437+0.j]\n"," [-1.77516687+0.j -2.54725756+0.j]\n"," [-1.63024483+0.j -2.302505  +0.j]\n"," [-1.42847467+0.j -1.96369972+0.j]\n"," [-1.50337736+0.j -2.06783361+0.j]\n"," [-1.48893461+0.j -2.11442674+0.j]\n"," [-1.35700838+0.j -1.75428449+0.j]\n"," [-1.3795792 +0.j -2.13271099+0.j]\n"," [-1.65506386+0.j -2.0431741 +0.j]\n"," [-1.04356034+0.j -1.92449977+0.j]\n"," [-1.12096094+0.j -1.699853  +0.j]\n"," [-1.17443134+0.j -1.54228363+0.j]\n"," [-1.18744274+0.j -1.93081847+0.j]\n"," [-1.46468272+0.j -1.86215146+0.j]\n"," [-1.48146353+0.j -1.82874656+0.j]\n"," [-1.18904953+0.j -1.65764616+0.j]\n"," [-1.17130335+0.j -1.5996383 +0.j]\n"," [-1.32634064+0.j -1.95868741+0.j]\n"," [-1.76713997+0.j -2.13717248+0.j]\n"," [-1.85304902+0.j -2.29999459+0.j]\n"," [-1.2475787 +0.j -1.62554765+0.j]\n"," [-1.47327677+0.j -1.76063036+0.j]\n"," [-1.63810761+0.j -1.91462335+0.j]\n"," [-1.56681676+0.j -1.86716377+0.j]\n"," [-1.21538977+0.j -1.61413292+0.j]\n"," [-1.40518817+0.j -1.80283721+0.j]\n"," [-1.46300166+0.j -1.98830268+0.j]\n"," [-0.89518633+0.j -1.28110404+0.j]\n"," [-1.2926305 +0.j -1.73145503+0.j]\n"," [-1.08459303+0.j -2.14337015+0.j]\n"," [-1.19659488+0.j -2.09034743+0.j]\n"," [-1.17275028+0.j -1.66843486+0.j]\n"," [-1.50426848+0.j -2.01222527+0.j]\n"," [-1.2789777 +0.j -1.70750527+0.j]\n"," [-1.56279764+0.j -1.98012676+0.j]\n"," [-1.40109479+0.j -1.76877911+0.j]\n"," [ 0.89710107+0.j -1.81307261+0.j]\n"," [ 0.98227886+0.j -1.93661105+0.j]\n"," [ 1.138133  +0.j -1.78019136+0.j]\n"," [ 1.09925388+0.j -1.37517293+0.j]\n"," [ 1.17128732+0.j -1.67736387+0.j]\n"," [ 1.14140953+0.j -1.54350383+0.j]\n"," [ 1.14607006+0.j -2.02105191+0.j]\n"," [ 0.58586528+0.j -1.37587196+0.j]\n"," [ 0.97032269+0.j -1.5827875 +0.j]\n"," [ 1.02272882+0.j -1.71005903+0.j]\n"," [ 0.83027492+0.j -1.09136863+0.j]\n"," [ 0.99768699+0.j -1.89179142+0.j]\n"," [ 0.82129822+0.j -1.08894193+0.j]\n"," [ 1.20082982+0.j -1.63121068+0.j]\n"," [ 0.6250528 +0.j -1.82881708+0.j]\n"," [ 0.83214047+0.j -1.82822043+0.j]\n"," [ 1.22651305+0.j -1.81406337+0.j]\n"," [ 0.72534591+0.j -1.35568466+0.j]\n"," [ 1.41023091+0.j -1.3486941 +0.j]\n"," [ 0.80426771+0.j -1.36451378+0.j]\n"," [ 1.4650584 +0.j -2.08841253+0.j]\n"," [ 0.78090694+0.j -1.67239739+0.j]\n"," [ 1.49510031+0.j -1.42430585+0.j]\n"," [ 1.0979801 +0.j -1.418659  +0.j]\n"," [ 0.84586754+0.j -1.65724957+0.j]\n"," [ 0.89163502+0.j -1.76890617+0.j]\n"," [ 1.14873208+0.j -1.55186584+0.j]\n"," [ 1.41537299+0.j -1.84885837+0.j]\n"," [ 1.18163669+0.j -1.7580151 +0.j]\n"," [ 0.45243343+0.j -1.44790734+0.j]\n"," [ 0.80836109+0.j -1.33045568+0.j]\n"," [ 0.68222488+0.j -1.27876652+0.j]\n"," [ 0.75601365+0.j -1.56008759+0.j]\n"," [ 1.6620195 +0.j -1.56610137+0.j]\n"," [ 1.26826142+0.j -1.81275697+0.j]\n"," [ 1.05926989+0.j -2.12826568+0.j]\n"," [ 1.06907902+0.j -1.82939727+0.j]\n"," [ 1.15386511+0.j -1.27937389+0.j]\n"," [ 0.86343829+0.j -1.76119736+0.j]\n"," [ 1.02201314+0.j -1.49249504+0.j]\n"," [ 1.13426242+0.j -1.37318617+0.j]\n"," [ 1.10680828+0.j -1.71512788+0.j]\n"," [ 0.85003519+0.j -1.47617038+0.j]\n"," [ 0.60361147+0.j -1.3178641 +0.j]\n"," [ 1.03470057+0.j -1.55995804+0.j]\n"," [ 0.82723024+0.j -1.6596491 +0.j]\n"," [ 0.93658565+0.j -1.67793335+0.j]\n"," [ 0.88761591+0.j -1.65594318+0.j]\n"," [ 0.41002808+0.j -1.58855318+0.j]\n"," [ 0.91980484+0.j -1.64452845+0.j]\n"," [ 2.50290064+0.j -2.38522969+0.j]\n"," [ 1.91597298+0.j -1.79563091+0.j]\n"," [ 2.11342696+0.j -1.93194701+0.j]\n"," [ 1.94063215+0.j -1.71299292+0.j]\n"," [ 2.25400592+0.j -2.0302293 +0.j]\n"," [ 2.39686425+0.j -1.75841992+0.j]\n"," [ 1.70720425+0.j -1.67007633+0.j]\n"," [ 2.11969853+0.j -1.54273181+0.j]\n"," [ 2.12241924+0.j -1.43044918+0.j]\n"," [ 2.25457307+0.j -2.54183547+0.j]\n"," [ 1.6474869 +0.j -2.17045387+0.j]\n"," [ 1.90153023+0.j -1.74903778+0.j]\n"," [ 1.95444482+0.j -2.03101204+0.j]\n"," [ 2.02942177+0.j -1.77985706+0.j]\n"," [ 2.23102781+0.j -2.23901851+0.j]\n"," [ 1.99136855+0.j -2.35012429+0.j]\n"," [ 1.80486225+0.j -1.79821652+0.j]\n"," [ 2.19316333+0.j -2.28005071+0.j]\n"," [ 2.83814514+0.j -1.60255105+0.j]\n"," [ 1.72898513+0.j -1.22110694+0.j]\n"," [ 2.10860232+0.j -2.25236566+0.j]\n"," [ 1.87903368+0.j -1.98044319+0.j]\n"," [ 2.43789694+0.j -1.53954954+0.j]\n"," [ 1.63006469+0.j -1.77246389+0.j]\n"," [ 1.97026024+0.j -2.1558297 +0.j]\n"," [ 1.85850809+0.j -1.79383024+0.j]\n"," [ 1.55691733+0.j -1.8557279 +0.j]\n"," [ 1.55595195+0.j -1.94714066+0.j]\n"," [ 2.17058346+0.j -1.88582099+0.j]\n"," [ 1.68347641+0.j -1.57312982+0.j]\n"," [ 2.09737742+0.j -1.61218156+0.j]\n"," [ 1.84374137+0.j -2.20323495+0.j]\n"," [ 2.2413185 +0.j -1.9627663 +0.j]\n"," [ 1.49004155+0.j -1.54977671+0.j]\n"," [ 1.81530147+0.j -1.22792212+0.j]\n"," [ 2.24045429+0.j -2.0392445 +0.j]\n"," [ 2.17194055+0.j -2.46797005+0.j]\n"," [ 1.78711606+0.j -1.85622438+0.j]\n"," [ 1.52142496+0.j -1.97174362+0.j]\n"," [ 1.8395491 +0.j -2.11558244+0.j]\n"," [ 2.20430493+0.j -2.29459967+0.j]\n"," [ 1.81481566+0.j -2.34524152+0.j]\n"," [ 1.91597298+0.j -1.79563091+0.j]\n"," [ 2.24027885+0.j -2.20120015+0.j]\n"," [ 2.2532004 +0.j -2.46361094+0.j]\n"," [ 1.95058557+0.j -2.26001792+0.j]\n"," [ 1.83344164+0.j -1.70683093+0.j]\n"," [ 1.78012881+0.j -2.0278756 +0.j]\n"," [ 2.01127735+0.j -2.44088385+0.j]\n"," [ 1.70850266+0.j -1.89532196+0.j]]\n"]}],"source":["import numpy as np\n","from numpy.linalg import eig\n","import pandas as pd\n","from sklearn.datasets import load_iris\n","\n","class LDA:\n","    def __init__(self, n_components=None):\n","        self.n_components = n_components\n","        self.linear_discriminants = None\n","\n","    def fit(self, X, y):\n","        X = np.array(X).astype(float)  # Ensure X is numerical\n","        n_features = X.shape[1]\n","        class_labels = np.unique(y)\n","\n","        # Step 1: Compute the mean vectors for each class\n","        mean_vectors = []\n","        for label in class_labels:\n","            mean_vectors.append(np.mean(X[y == label], axis=0))\n","\n","        # Step 2: Compute within-class scatter matrix (Sw)\n","        Sw = np.zeros((n_features, n_features))\n","        for label, mean_vec in zip(class_labels, mean_vectors):\n","            class_scatter = np.zeros((n_features, n_features))\n","            for row in X[y == label]:\n","                row, mean_vec = row.reshape(n_features, 1), mean_vec.reshape(n_features, 1)\n","                class_scatter += (row - mean_vec).dot((row - mean_vec).T)\n","            Sw += class_scatter\n","\n","        # Step 3: Compute between-class scatter matrix (Sb)\n","        overall_mean = np.mean(X, axis=0).reshape(n_features, 1)\n","        Sb = np.zeros((n_features, n_features))\n","        for label, mean_vec in zip(class_labels, mean_vectors):\n","            n = X[y == label].shape[0]\n","            mean_vec = mean_vec.reshape(n_features, 1)\n","            Sb += n * (mean_vec - overall_mean).dot((mean_vec - overall_mean).T)\n","\n","        # Step 4: Solve the eigenvalue problem for Sw^(-1) * Sb\n","        eig_vals, eig_vecs = eig(np.linalg.inv(Sw).dot(Sb))\n","\n","        # Step 5: Sort eigenvalues and eigenvectors in decreasing order\n","        eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:, i]) for i in range(len(eig_vals))]\n","        eig_pairs = sorted(eig_pairs, key=lambda x: x[0], reverse=True)\n","\n","        # Step 6: Select top k eigenvectors\n","        self.linear_discriminants = np.array([eig_pairs[i][1] for i in range(self.n_components)]).T\n","\n","    def transform(self, X):\n","        X = np.array(X).astype(float)  # Ensure X is numerical\n","        return np.dot(X, self.linear_discriminants)\n","\n","# Load Iris dataset\n","iris = load_iris()\n","X = pd.DataFrame(iris.data, columns=iris.feature_names)\n","y = pd.Series(iris.target, name='target')\n","\n","# Apply LDA\n","lda = LDA(n_components=2)\n","lda.fit(X, y)\n","X_lda = lda.transform(X)\n","\n","# Print the transformed data\n","print(\"Transformed Data:\\n\", X_lda)\n"]},{"cell_type":"markdown","source":["# By using Sklearn Library"],"metadata":{"id":"mATpDhvw0QUG"}},{"cell_type":"code","source":["from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n","lda = LDA(n_components=2)\n","X_train_lda = lda.fit_transform(X, y)"],"metadata":{"id":"L6Za1lcDz3kV","executionInfo":{"status":"ok","timestamp":1730570220001,"user_tz":-330,"elapsed":475,"user":{"displayName":"Gk sah","userId":"05182244052629094637"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["X_train_lda"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4HsssoVl0lBX","executionInfo":{"status":"ok","timestamp":1730570223040,"user_tz":-330,"elapsed":551,"user":{"displayName":"Gk sah","userId":"05182244052629094637"}},"outputId":"d149e2e7-dcf3-4981-851f-73bf19c9b0ea"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 8.06179978e+00, -3.00420621e-01],\n","       [ 7.12868772e+00,  7.86660426e-01],\n","       [ 7.48982797e+00,  2.65384488e-01],\n","       [ 6.81320057e+00,  6.70631068e-01],\n","       [ 8.13230933e+00, -5.14462530e-01],\n","       [ 7.70194674e+00, -1.46172097e+00],\n","       [ 7.21261762e+00, -3.55836209e-01],\n","       [ 7.60529355e+00,  1.16338380e-02],\n","       [ 6.56055159e+00,  1.01516362e+00],\n","       [ 7.34305989e+00,  9.47319209e-01],\n","       [ 8.39738652e+00, -6.47363392e-01],\n","       [ 7.21929685e+00,  1.09646389e-01],\n","       [ 7.32679599e+00,  1.07298943e+00],\n","       [ 7.57247066e+00,  8.05464137e-01],\n","       [ 9.84984300e+00, -1.58593698e+00],\n","       [ 9.15823890e+00, -2.73759647e+00],\n","       [ 8.58243141e+00, -1.83448945e+00],\n","       [ 7.78075375e+00, -5.84339407e-01],\n","       [ 8.07835876e+00, -9.68580703e-01],\n","       [ 8.02097451e+00, -1.14050366e+00],\n","       [ 7.49680227e+00,  1.88377220e-01],\n","       [ 7.58648117e+00, -1.20797032e+00],\n","       [ 8.68104293e+00, -8.77590154e-01],\n","       [ 6.25140358e+00, -4.39696367e-01],\n","       [ 6.55893336e+00,  3.89222752e-01],\n","       [ 6.77138315e+00,  9.70634453e-01],\n","       [ 6.82308032e+00, -4.63011612e-01],\n","       [ 7.92461638e+00, -2.09638715e-01],\n","       [ 7.99129024e+00, -8.63787128e-02],\n","       [ 6.82946447e+00,  5.44960851e-01],\n","       [ 6.75895493e+00,  7.59002759e-01],\n","       [ 7.37495254e+00, -5.65844592e-01],\n","       [ 9.12634625e+00, -1.22443267e+00],\n","       [ 9.46768199e+00, -1.82522635e+00],\n","       [ 7.06201386e+00,  6.63400423e-01],\n","       [ 7.95876243e+00,  1.64961722e-01],\n","       [ 8.61367201e+00, -4.03253602e-01],\n","       [ 8.33041759e+00, -2.28133530e-01],\n","       [ 6.93412007e+00,  7.05519379e-01],\n","       [ 7.68823131e+00,  9.22362309e-03],\n","       [ 7.91793715e+00, -6.75121313e-01],\n","       [ 5.66188065e+00,  1.93435524e+00],\n","       [ 7.24101468e+00,  2.72615132e-01],\n","       [ 6.41443556e+00, -1.24730131e+00],\n","       [ 6.85944381e+00, -1.05165396e+00],\n","       [ 6.76470393e+00,  5.05151855e-01],\n","       [ 8.08189937e+00, -7.63392750e-01],\n","       [ 7.18676904e+00,  3.60986823e-01],\n","       [ 8.31444876e+00, -6.44953177e-01],\n","       [ 7.67196741e+00,  1.34893840e-01],\n","       [-1.45927545e+00, -2.85437643e-02],\n","       [-1.79770574e+00, -4.84385502e-01],\n","       [-2.41694888e+00,  9.27840307e-02],\n","       [-2.26247349e+00,  1.58725251e+00],\n","       [-2.54867836e+00,  4.72204898e-01],\n","       [-2.42996725e+00,  9.66132066e-01],\n","       [-2.44848456e+00, -7.95961954e-01],\n","       [-2.22666513e-01,  1.58467318e+00],\n","       [-1.75020123e+00,  8.21180130e-01],\n","       [-1.95842242e+00,  3.51563753e-01],\n","       [-1.19376031e+00,  2.63445570e+00],\n","       [-1.85892567e+00, -3.19006544e-01],\n","       [-1.15809388e+00,  2.64340991e+00],\n","       [-2.66605725e+00,  6.42504540e-01],\n","       [-3.78367218e-01, -8.66389312e-02],\n","       [-1.20117255e+00, -8.44373592e-02],\n","       [-2.76810246e+00, -3.21995363e-02],\n","       [-7.76854039e-01,  1.65916185e+00],\n","       [-3.49805433e+00,  1.68495616e+00],\n","       [-1.09042788e+00,  1.62658350e+00],\n","       [-3.71589615e+00, -1.04451442e+00],\n","       [-9.97610366e-01,  4.90530602e-01],\n","       [-3.83525931e+00,  1.40595806e+00],\n","       [-2.25741249e+00,  1.42679423e+00],\n","       [-1.25571326e+00,  5.46424197e-01],\n","       [-1.43755762e+00,  1.34424979e-01],\n","       [-2.45906137e+00,  9.35277280e-01],\n","       [-3.51848495e+00, -1.60588866e-01],\n","       [-2.58979871e+00,  1.74611728e-01],\n","       [ 3.07487884e-01,  1.31887146e+00],\n","       [-1.10669179e+00,  1.75225371e+00],\n","       [-6.05524589e-01,  1.94298038e+00],\n","       [-8.98703769e-01,  9.04940034e-01],\n","       [-4.49846635e+00,  8.82749915e-01],\n","       [-2.93397799e+00, -2.73791065e-02],\n","       [-2.10360821e+00, -1.19156767e+00],\n","       [-2.14258208e+00, -8.87797815e-02],\n","       [-2.47945603e+00,  1.94073927e+00],\n","       [-1.32552574e+00,  1.62869550e-01],\n","       [-1.95557887e+00,  1.15434826e+00],\n","       [-2.40157020e+00,  1.59458341e+00],\n","       [-2.29248878e+00,  3.32860296e-01],\n","       [-1.27227224e+00,  1.21458428e+00],\n","       [-2.93176055e-01,  1.79871509e+00],\n","       [-2.00598883e+00,  9.05418042e-01],\n","       [-1.18166311e+00,  5.37570242e-01],\n","       [-1.61615645e+00,  4.70103580e-01],\n","       [-1.42158879e+00,  5.51244626e-01],\n","       [ 4.75973788e-01,  7.99905482e-01],\n","       [-1.54948259e+00,  5.93363582e-01],\n","       [-7.83947399e+00, -2.13973345e+00],\n","       [-5.50747997e+00,  3.58139892e-02],\n","       [-6.29200850e+00, -4.67175777e-01],\n","       [-5.60545633e+00,  3.40738058e-01],\n","       [-6.85055995e+00, -8.29825394e-01],\n","       [-7.41816784e+00,  1.73117995e-01],\n","       [-4.67799541e+00,  4.99095015e-01],\n","       [-6.31692685e+00,  9.68980756e-01],\n","       [-6.32773684e+00,  1.38328993e+00],\n","       [-6.85281335e+00, -2.71758963e+00],\n","       [-4.44072512e+00, -1.34723692e+00],\n","       [-5.45009572e+00,  2.07736942e-01],\n","       [-5.66033713e+00, -8.32713617e-01],\n","       [-5.95823722e+00,  9.40175447e-02],\n","       [-6.75926282e+00, -1.60023206e+00],\n","       [-5.80704331e+00, -2.01019882e+00],\n","       [-5.06601233e+00,  2.62733839e-02],\n","       [-6.60881882e+00, -1.75163587e+00],\n","       [-9.17147486e+00,  7.48255067e-01],\n","       [-4.76453569e+00,  2.15573720e+00],\n","       [-6.27283915e+00, -1.64948141e+00],\n","       [-5.36071189e+00, -6.46120732e-01],\n","       [-7.58119982e+00,  9.80722934e-01],\n","       [-4.37150279e+00,  1.21297458e-01],\n","       [-5.72317531e+00, -1.29327553e+00],\n","       [-5.27915920e+00,  4.24582377e-02],\n","       [-4.08087208e+00, -1.85936572e-01],\n","       [-4.07703640e+00, -5.23238483e-01],\n","       [-6.51910397e+00, -2.96976389e-01],\n","       [-4.58371942e+00,  8.56815813e-01],\n","       [-6.22824009e+00,  7.12719638e-01],\n","       [-5.22048773e+00, -1.46819509e+00],\n","       [-6.80015000e+00, -5.80895175e-01],\n","       [-3.81515972e+00,  9.42985932e-01],\n","       [-5.10748966e+00,  2.13059000e+00],\n","       [-6.79671631e+00, -8.63090395e-01],\n","       [-6.52449599e+00, -2.44503527e+00],\n","       [-4.99550279e+00, -1.87768525e-01],\n","       [-3.93985300e+00, -6.14020389e-01],\n","       [-5.20383090e+00, -1.14476808e+00],\n","       [-6.65308685e+00, -1.80531976e+00],\n","       [-5.10555946e+00, -1.99218201e+00],\n","       [-5.50747997e+00,  3.58139892e-02],\n","       [-6.79601924e+00, -1.46068695e+00],\n","       [-6.84735943e+00, -2.42895067e+00],\n","       [-5.64500346e+00, -1.67771734e+00],\n","       [-5.17956460e+00,  3.63475041e-01],\n","       [-4.96774090e+00, -8.21140550e-01],\n","       [-5.88614539e+00, -2.34509051e+00],\n","       [-4.68315426e+00, -3.32033811e-01]])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy_score(y, lda.predict(X))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hk71cyqEBNsD","executionInfo":{"status":"ok","timestamp":1730570230195,"user_tz":-330,"elapsed":487,"user":{"displayName":"Gk sah","userId":"05182244052629094637"}},"outputId":"4f9fe173-0658-4fee-d4d5-053e0faac6bd"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.98"]},"metadata":{},"execution_count":5}]}]}